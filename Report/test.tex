%! Author = Miszka and Tamarka
%! Date = 10.03.2022

% Preamble
\documentclass[11pt]{amsart}

% Packages
\usepackage{float}
\usepackage[T1]{fontenc}
\usepackage{geometry}
\usepackage{parskip}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{titling}
%\usepackage{itemize}
\usepackage{enumerate}
\usepackage{multirow}
\usepackage{graphics}
\usepackage{caption}
\usepackage{array}
\setlength{\droptitle}{-2cm}
%\newgeometry{tmargin=1.9cm, bmargin=1.9cm, lmargin=1.7cm, rmargin=1.7cm}

\DeclareMathOperator*{\argmin}{arg\,min}


\author{Tamara FrÄ…czek, Dominik Mika}
\title{Methods of classification and dimensionality reduction - Report 1}
\date{\today}

% Document
\begin{document}
\maketitle


\section{Description of methods}
\subsection*{SVD1}

We get a $n \times d$ dimensional matrix $Z$ that we want to approximate by a different matrix $\tilde{Z}$.
We want somehow $\tilde{Z}$ to maintain only ''the most important'' informations from $Z$.
That's what we can get using SVD decomposition of matrix and cutting out the smallest eigenvalues.

Presicely, we want to find matrix $\tilde{Z}_r$ of rank $r$ ($r < rank(Z)$), so that $\|Z - \tilde{Z}_r\|$ is small.
Using SVD decomposition $Z = U \Lambda^{\frac{1}{2}} V^T$ we construct $\tilde{Z}$ as
\[\tilde{Z}_r = U_r \Lambda_r^{\frac{1}{2}}V_r^T,\]
where $\Lambda_r$ contains $r$ biggest eigenvalues of $Z$ and $U_r$, $V_r$ contains only columns corresponding to those eigenvalues.


\subsection*{NMF}
We get a real $n \times d$ dimensional matrix $Z$, such that $n \ge d$.
The aim is to approximate $Z$ as
\[Z \approx WH,\]
where
\begin{itemize}
    \item $W$ is $n \times r$ matrix of nonegative elements,
    \item $H$ is $r \times d$ matrix of nonnegative elements.
\end{itemize}
Precisely, we look for
\[\argmin_{W, H} \|Z - WH \|^2,\]
where $\|A\|^2 = \sum_{i, j} A_{ij}^2$.


\subsection*{SVD2}

\section{Our data}
\subsection*{Description}
\subsection*{Performing methods}
\subsection*{Choosing parameters}

\section{Results}



\end{document}